{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "EeqYa9bzWObq"
      },
      "source": [
        "# üìç NutriChef AI - Phase 2: Gradio Frontend App\n",
        "This notebook creates the frontend UI for NutriChef AI using Gradio.\n",
        "Users can upload a fridge photo or record their voice to get meal plans, recipes, nutrition facts, and health advice."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "XLF6nJbRtX-Q",
        "outputId": "590b4f65-70d5-4196-f54d-3dae1a22fe1d"
      },
      "outputs": [],
      "source": [
        "# from google.colab import drive\n",
        "# drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HzNDaIzQWvlN"
      },
      "source": [
        "## üìçStep 1: Install and Import Basic Libraries"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "IXpUZuc7brrt",
        "outputId": "325456d4-fd14-4ae3-ac5d-a2283445fae2"
      },
      "outputs": [],
      "source": [
        "# Move to project folder (only if you're on Colab and this path is correct)\n",
        "%cd /content/drive/MyDrive/Colab Notebooks/NutriChefAI\n",
        "\n",
        "# Whisper (speech-to-text from audio/video)\n",
        "!pip install git+https://github.com/openai/whisper.git\n",
        "\n",
        "# YouTube downloader\n",
        "!pip install yt-dlp\n",
        "\n",
        "# LangChain ecosystem + LangSmith for tracing\n",
        "!pip install langchain langchain-community langchain-openai langsmith\n",
        "\n",
        "# Core model libraries\n",
        "!pip install openai huggingface_hub transformers\n",
        "\n",
        "# Vector database + embedding models\n",
        "!pip install chromadb sentence-transformers\n",
        "\n",
        "# Gradio for app UI\n",
        "!pip install gradio"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0AdRHgZjWYWL"
      },
      "source": [
        "### Import Needed Libraries"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "TF8kEe8zMU62"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "\n",
        "# Set LangSmith credentials\n",
        "os.environ[\"LANGCHAIN_TRACING_V2\"] = \"true\"\n",
        "os.environ[\"LANGCHAIN_API_KEY\"] = \"\"\n",
        "os.environ[\"LANGCHAIN_PROJECT\"] = \"NutriChefAI\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "-FAzLEyINj9T"
      },
      "outputs": [],
      "source": [
        "# from langsmith import Client\n",
        "\n",
        "# client = Client()\n",
        "# project = client.read_project(project_name=\"NutriChefAI\")\n",
        "# print(f\"‚úÖ LangSmith connected to project: {project.name}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "20wrh-vEZWnO"
      },
      "outputs": [],
      "source": [
        "# === Imports ===\n",
        "import gradio as gr\n",
        "import os\n",
        "import sys\n",
        "import random\n",
        "import json\n",
        "import yt_dlp\n",
        "import whisper\n",
        "import ast\n",
        "import re\n",
        "import chromadb\n",
        "import pandas as pd\n",
        "# from langchain.chat_models import ChatOpenAI\n",
        "from langchain.prompts import ChatPromptTemplate\n",
        "from langchain.chains import LLMChain\n",
        "from chromadb.config import Settings\n",
        "from chromadb import PersistentClient\n",
        "from sentence_transformers import SentenceTransformer\n",
        "from langchain.vectorstores import Chroma\n",
        "from langchain.embeddings import HuggingFaceEmbeddings\n",
        "# from langchain.chat_models import ChatOpenAI\n",
        "from langchain.chains import RetrievalQA\n",
        "from langsmith import traceable\n",
        "from tqdm import tqdm\n",
        "\n",
        "from langchain.tools import Tool\n",
        "\n",
        "from langchain_core.runnables.history import RunnableWithMessageHistory\n",
        "from langchain_core.chat_history import InMemoryChatMessageHistory\n",
        "from langchain_core.prompts import ChatPromptTemplate, MessagesPlaceholder\n",
        "from langchain_openai import ChatOpenAI\n",
        "\n",
        "# Load the cleaned recipe dataset with nutrition column\n",
        "recipes_df = pd.read_csv(\"./database/recipes.csv\")\n",
        "# Rename if needed\n",
        "recipes_df[\"recipe_name\"] = recipes_df[\"recipe_name\"].str.lower().str.strip()\n",
        "recipes_df = recipes_df.rename(columns={\"recipe_name\": \"name\"})\n",
        "\n",
        "#++++++++++++++++++++++++++++++\n",
        "\n",
        "# Load RAW_recipes (limit to useful columns)\n",
        "raw_df = pd.read_csv(\"./database/RAW_recipes.csv\", usecols=[\n",
        "    \"name\", \"minutes\", \"nutrition\", \"steps\", \"description\", \"ingredients\"\n",
        "])\n",
        "\n",
        "# Standardize text fields\n",
        "raw_df[\"name\"] = raw_df[\"name\"].str.lower().str.strip()\n",
        "raw_df[\"description\"] = raw_df[\"description\"].fillna(\"\")\n",
        "raw_df[\"steps\"] = raw_df[\"steps\"].apply(ast.literal_eval).apply(lambda x: \" \".join(x) if isinstance(x, list) else \"\")\n",
        "raw_df[\"ingredients\"] = raw_df[\"ingredients\"].apply(ast.literal_eval).apply(lambda x: \", \".join(x) if isinstance(x, list) else \"\")\n",
        "\n",
        "# Convert nutrition to string for safety if needed\n",
        "raw_df[\"nutrition\"] = raw_df[\"nutrition\"].apply(lambda x: str(x) if isinstance(x, list) else x)\n",
        "\n",
        "# Add empty columns to raw_df to match existing schema if needed\n",
        "raw_df[\"primaryCategories\"] = \"general\"\n",
        "raw_df[\"cuisine_path\"] = \"unknown\"\n",
        "raw_df[\"timing\"] = raw_df[\"minutes\"].astype(str) + \" minutes\"\n",
        "\n",
        "combined_df = pd.concat([recipes_df, raw_df], ignore_index=True)\n",
        "\n",
        "#+++++++++++++++++++++++++++++++\n",
        "\n",
        "# Add models/utils folder to path if needed\n",
        "sys.path.append('./')\n",
        "\n",
        "# Import backend modules\n",
        "from models.vision_model import IngredientDetector\n",
        "# from models.speech_to_text import SpeechToText\n",
        "from models.meal_generator import create_daily_meal_plan\n",
        "from models.food_classifier import FoodClassifier\n",
        "# from utils.recipe_retriever import embed_query, search_recipes\n",
        "# from utils.nutrition_generator import generate_nutrition_facts_and_advice\n",
        "\n",
        "\n",
        "# For vector database and OpenAI\n",
        "\n",
        "from openai import OpenAI\n",
        "from PIL import Image\n",
        "os.makedirs(\"./downloads\", exist_ok=True)\n",
        "os.environ[\"OPENAI_API_KEY\"] = \"\"\n",
        "# from huggingface_hub import login\n",
        "# login(token=\"\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KESIs8fpZk2a"
      },
      "source": [
        "### Setup Clients and Models Once"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "tjo6rGWKlAlC"
      },
      "outputs": [],
      "source": [
        "class SpeechToText:\n",
        "    def __init__(self):\n",
        "        import whisper\n",
        "        self.model = whisper.load_model(\"base\")\n",
        "\n",
        "    def extract_ingredients(self, audio_file_path):\n",
        "        try:\n",
        "            result = self.model.transcribe(audio_file_path)\n",
        "            text = result[\"text\"]\n",
        "            ingredients = [x.strip() for x in text.split(\",\") if x.strip()]\n",
        "            return ingredients\n",
        "        except Exception as e:\n",
        "            print(f\"üî• Error transcribing audio: {e}\")\n",
        "            return []"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "UjNcliNFWlSM"
      },
      "outputs": [],
      "source": [
        "# rm -rf ./database/vector_store"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 341,
          "referenced_widgets": [
            "696e94322bde45429eb382e6131ee713",
            "34582e88f5634016b1734b7454fa513f",
            "05c1bf9e69034a4da04987e5f1db0da2",
            "cc5b6a9306e24866b435aa735994cf0e",
            "6e0f4a000c3c4064872acb242b595be0",
            "ead270f9e4c54b04938d1656b1ba5722",
            "3cb6d5e84e624bd297af584d8c4aa55a",
            "326c3d2c214f4da4a71863164ac7b2f8",
            "9b7b5890a3ec40faaed455580a5c975b",
            "2049e5a7e7034ee9a474f0660afda01b",
            "027da485715142c38a2c26789c73d7b2",
            "042b770a7a974f44a90b57e67653f88b",
            "afda3fe3b30246fcaaed8dbbb10da920",
            "1df5977bb6eb440dbac7806db50544d4",
            "79b11639e16540eb895603f7e91a17d4",
            "859f5ba18cb547008dcaa867f7b85be0",
            "f6901a26bf4442d5a0a80db84eb0eac9",
            "4dc5b4b7f68340ea8f55cc79a523fa36",
            "fba2200969c64ee0afec16ea7bde00a5",
            "94bb5e8bb23f42098d7f42d0961e8321",
            "1c916077648a41148c42103ec65eccea",
            "50a7dde59a6b4a169c2f6e1250e97206",
            "9a8e21dbb5804af880a6133a836a030f",
            "23c205f825454f02ac00e12021f259ff",
            "61553f3c015841b587983d99c9eea071",
            "eec68c0b6c444ad9a0ec7e89a29594f1",
            "d68ddb5cc69d49d4bb53e1fdf46836c5",
            "64113a256757492592f1520842eb2d68",
            "0423a2e9a0c348ef98ee471c0c25eb3c",
            "e9915487dff84ead82431d5f6ca1f39d",
            "addf25ab3bfb4b20ac9b754f5a1a00ae",
            "971185292cf747e593dd19c173f48f61",
            "cd53374fd02748e08b8683ade74a002e"
          ]
        },
        "id": "oE7e0pJGZmuS",
        "outputId": "e2ce883b-1ee5-4fc4-b8cf-0d36fa0ddb21"
      },
      "outputs": [],
      "source": [
        "from chromadb.errors import NotFoundError\n",
        "# === Setup backend models ===\n",
        "\n",
        "# Vision model (Image captioning)\n",
        "vision_detector = IngredientDetector()\n",
        "\n",
        "# Whisper model (Speech to Text)\n",
        "speech_detector = SpeechToText()\n",
        "\n",
        "# Embedding model\n",
        "# embedding_model = SentenceTransformer(\"all-MiniLM-L6-v2\")\n",
        "embedding_model = HuggingFaceEmbeddings(model_name=\"all-MiniLM-L6-v2\")\n",
        "\n",
        "#+++++++++++++++++++++++++++++++++\n",
        "# Clear and re-add all data\n",
        "docs = combined_df[\"description\"].fillna(\"\") + \". \" + combined_df[\"steps\"].fillna(\"\")\n",
        "metadatas = combined_df[[\"name\", \"ingredients\", \"timing\", \"cuisine_path\"]].to_dict(orient=\"records\")\n",
        "\n",
        "#+++++++++++++++++++++++++++++++++\n",
        "# Vector store (ChromaDB)\n",
        "# chroma_client = chromadb.PersistentClient(path=\"./database/vector_store\")\n",
        "# chroma_client = PersistentClient(path=\"./database/vector_store\")\n",
        "\n",
        "# collection = chroma_client.get_or_create_collection(name=\"recipes\") ***\n",
        "\n",
        "#++++++++++++++++++++++++++++++++\n",
        "# Re-create the collection from scratch\n",
        "# Initialize persistent client\n",
        "chroma_client = PersistentClient(path=\"./database/vector_store\")\n",
        "\n",
        "# Try deleting only if exists\n",
        "try:\n",
        "    chroma_client.delete_collection(\"recipes\")\n",
        "    print(\"üóëÔ∏è Old 'recipes' collection deleted.\")\n",
        "except NotFoundError:\n",
        "    print(\"‚ö†Ô∏è No existing 'recipes' collection found. Skipping deletion.\")\n",
        "\n",
        "collection = chroma_client.get_or_create_collection(\"recipes\")\n",
        "\n",
        "def batched_add_to_chroma(collection, docs, embeddings, metadatas, batch_size=5000):\n",
        "    for i in range(0, len(docs), batch_size):\n",
        "        batch_docs = docs[i:i+batch_size]\n",
        "        batch_embeddings = embeddings[i:i+batch_size]\n",
        "        batch_metadatas = metadatas[i:i+batch_size]\n",
        "        batch_ids = [f\"recipe_{j}\" for j in range(i, i+len(batch_docs))]\n",
        "\n",
        "        collection.add(\n",
        "            documents=batch_docs,\n",
        "            embeddings=batch_embeddings,\n",
        "            metadatas=batch_metadatas,\n",
        "            ids=batch_ids\n",
        "        )\n",
        "\n",
        "# ‚úÖ No need to clear manually ‚Äî collection was just deleted\n",
        "\n",
        "# Embed everything first\n",
        "all_docs = docs.tolist()\n",
        "all_embeddings = embedding_model.embed_documents(all_docs)\n",
        "all_metadatas = metadatas\n",
        "\n",
        "# Add in batches\n",
        "batched_add_to_chroma(collection, all_docs, all_embeddings, all_metadatas)\n",
        "\n",
        "#++++++++++++++++++++++++++++++++\n",
        "\n",
        "\n",
        "# Connect to a persistent Chroma client\n",
        "\n",
        "video_collection = chroma_client.get_or_create_collection(name=\"youtube_videos\")\n",
        "\n",
        "# OpenAI Client\n",
        "client = OpenAI()\n",
        "\n",
        "# Load Whisper model\n",
        "whisper_model = whisper.load_model(\"base\")\n",
        "\n",
        "food_detector = FoodClassifier()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "vyFkx_BfH19E"
      },
      "outputs": [],
      "source": [
        "\n",
        "# 1. Prompt template\n",
        "\n",
        "chat_prompt = ChatPromptTemplate.from_messages([\n",
        "    (\"system\", \"\"\"You are NutriChef AI, a professional and friendly culinary assistant.\n",
        "\n",
        "- You always remember the user's recent questions and give clear, complete, and helpful answers.\n",
        "- If a user follows up with something like 'is it healthy?' or 'how to make it?', assume it's about the last discussed dish.\n",
        "- Respond confidently. Do not ask for clarification unless absolutely necessary.\n",
        "- Avoid repeating or restating the user‚Äôs question in replies.\n",
        "\"\"\"),\n",
        "    MessagesPlaceholder(variable_name=\"history\"),\n",
        "    (\"human\", \"{input}\")\n",
        "])\n",
        "\n",
        "# üîÅ Chain with memory\n",
        "chat_model = ChatOpenAI(model=\"gpt-3.5-turbo\", temperature=0.3)\n",
        "memory_chain = RunnableWithMessageHistory(\n",
        "    chat_prompt | chat_model,\n",
        "    lambda session_id: InMemoryChatMessageHistory(),\n",
        "    input_messages_key=\"input\",\n",
        "    history_messages_key=\"history\"\n",
        ")\n",
        "\n",
        "# Gradio States (for memory)\n",
        "ingredients_state = gr.State(\"\")\n",
        "meal_plan_state = gr.State({})"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "IL7g7MibH7g7"
      },
      "outputs": [],
      "source": [
        "import uuid\n",
        "\n",
        "def get_session_id():\n",
        "    return str(uuid.uuid4())\n",
        "\n",
        "session_id = gr.State(get_session_id())\n",
        "chat_history = gr.State([])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ASqv3rgQZw5D"
      },
      "source": [
        "## üìçStep 2: Write Backend Helper Functions"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "kyQCDLCjE74N"
      },
      "outputs": [],
      "source": [
        "\n",
        "def extract_dish_name(user_message: str) -> str:\n",
        "    \"\"\"\n",
        "    Extracts a likely dish or food item from the user message using general NLP rules.\n",
        "    \"\"\"\n",
        "    user_message = user_message.lower()\n",
        "\n",
        "    # Explicit patterns\n",
        "    patterns = [\n",
        "        r\"(?:how to make|recipe for|cook|prepare|want(?: to try)?|suggest(?: me)?|make)\\s+([a-zA-Z\\s]+)\",\n",
        "        r\"(?:i(?:'d)? like|give me|something like)\\s+([a-zA-Z\\s]+)\",\n",
        "    ]\n",
        "\n",
        "    for pattern in patterns:\n",
        "        match = re.search(pattern, user_message)\n",
        "        if match:\n",
        "            candidate = match.group(1).strip()\n",
        "            candidate = re.sub(r\"\\b(for dinner|for lunch|please|recipe)?\\b\", \"\", candidate).strip()\n",
        "            if 1 <= len(candidate.split()) <= 6:\n",
        "                return candidate\n",
        "\n",
        "    # Fallback: last 2‚Äì4 words as a potential noun phrase\n",
        "    tokens = user_message.split()\n",
        "    if len(tokens) >= 2:\n",
        "        fallback = \" \".join(tokens[-4:])  # last 4 words\n",
        "        return fallback.strip()\n",
        "\n",
        "    return \"\"\n",
        "\n",
        "def detect_dish_with_llm(message):\n",
        "    prompt = f\"\"\"\n",
        "You're a food assistant. Extract the specific dish or food name the user is referring to in this message:\n",
        "\n",
        "\"{message}\"\n",
        "\n",
        "If no dish is mentioned, return \"none\".\n",
        "Only return the dish name.\n",
        "\"\"\"\n",
        "    response = client.chat.completions.create(\n",
        "        model=\"gpt-3.5-turbo\",\n",
        "        messages=[{\"role\": \"user\", \"content\": prompt}]\n",
        "    )\n",
        "    return response.choices[0].message.content.strip()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "o1L2UUC481Zk"
      },
      "outputs": [],
      "source": [
        "#--------------------------------------------------------\n",
        "#       üßº Preprocessing / Input Handling\n",
        "#--------------------------------------------------------\n",
        "\n",
        "def resize_image(image, size=(384, 384)):\n",
        "    \"\"\"\n",
        "    Safely resize uploaded image for vision models.\n",
        "    \"\"\"\n",
        "    return image.resize(size)\n",
        "#_______________________\n",
        "\n",
        "@traceable(name=\"ProcessImagePipeline\")\n",
        "def process_image(image, mode=\"Generate New Meal Plan\"):\n",
        "    \"\"\"\n",
        "    Handles image > ingredients > generate meal OR search recipes based on user mode.\n",
        "    \"\"\"\n",
        "    try:\n",
        "        if image is None:\n",
        "            return \"‚ùå Please upload a valid image.\"\n",
        "\n",
        "        print(\"üì∏ Processing image...\")\n",
        "        image = resize_image(image)\n",
        "\n",
        "        ingredients, caption = vision_detector.detect_ingredients(image)\n",
        "        print(f\"‚úÖ Detected Ingredients: {ingredients}\")\n",
        "\n",
        "        if not ingredients:\n",
        "            return \"‚ùå No ingredients could be detected from the image.\"\n",
        "\n",
        "        if mode == \"Generate New Meal Plan\":\n",
        "            meal_plan = generate_meal_plan(ingredients)\n",
        "            nutrition = generate_nutrition_facts_and_advice(meal_plan)\n",
        "            return format_output(ingredients, meal_plan, nutrition)\n",
        "\n",
        "        elif mode == \"Search Existing Recipes\":\n",
        "            ingredient_query = \", \".join(ingredients)\n",
        "            recipes = search_recipes(ingredient_query)\n",
        "            return f\"\"\"üß∫ **Detected Ingredients**:\n",
        "{ingredient_query}\n",
        "\n",
        "üìö **Top Recipes**:\n",
        "\"\"\" + \"\\n\\n\".join(recipes)\n",
        "\n",
        "        else:\n",
        "            return \"‚ùå Invalid mode selected.\"\n",
        "\n",
        "    except Exception as e:\n",
        "        print(f\"üî• Error in process_image(): {e}\")\n",
        "        return \"‚ùå An unexpected error occurred.\"\n",
        "\n",
        "\n",
        "\n",
        "# === Vision Model for Ingredient Detection ===\n",
        "\n",
        "class IngredientDetector:\n",
        "    \"\"\"\n",
        "    Loads a BLIP model for ingredient detection from images.\n",
        "    \"\"\"\n",
        "    def __init__(self, device=None):\n",
        "        import torch\n",
        "        from transformers import BlipProcessor, BlipForConditionalGeneration\n",
        "\n",
        "        self.device = device or (\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "        self.processor = BlipProcessor.from_pretrained(\"Salesforce/blip-image-captioning-base\")\n",
        "        self.model = BlipForConditionalGeneration.from_pretrained(\"Salesforce/blip-image-captioning-base\").to(self.device)\n",
        "\n",
        "    def detect_ingredients(self, image):\n",
        "        \"\"\"\n",
        "        Detects ingredients and generates a caption from the image.\n",
        "        \"\"\"\n",
        "        try:\n",
        "            inputs = self.processor(image, return_tensors=\"pt\").to(self.device)\n",
        "            output = self.model.generate(**inputs)\n",
        "            caption = self.processor.decode(output[0], skip_special_tokens=True)\n",
        "\n",
        "            # Extract ingredients from caption simply (split commas)\n",
        "            ingredients_list = [x.strip() for x in caption.split(',') if x.strip()]\n",
        "            return ingredients_list, caption\n",
        "        except Exception as e:\n",
        "            print(f\"üî• Error detecting ingredients: {e}\")\n",
        "            return [], \"Error\"\n",
        "\n",
        "\n",
        "\n",
        "#_______________________\n",
        "\n",
        "@traceable(name=\"ExtractIngredientsFromAudio\")\n",
        "def extract_ingredients(audio_path):\n",
        "    \"\"\"\n",
        "    Transcribes the audio and extracts ingredients using GPT.\n",
        "    \"\"\"\n",
        "    try:\n",
        "        print(f\"üé§ Transcribing audio from: {audio_path}\")\n",
        "        result = whisper_model.transcribe(audio_path)\n",
        "        full_text = result[\"text\"]\n",
        "        print(f\"üìù Transcription: {full_text}\")\n",
        "\n",
        "        # Extract ingredients using GPT\n",
        "        prompt = f\"\"\"\n",
        "You're a kitchen assistant. The user said:\n",
        "\n",
        "\"{full_text}\"\n",
        "\n",
        "From this sentence, extract and return only the list of ingredients mentioned (just food items).\n",
        "Return them as a Python list. Do not include extra commentary.\n",
        "\"\"\"\n",
        "\n",
        "        response = client.chat.completions.create(\n",
        "            model=\"gpt-3.5-turbo\",\n",
        "            messages=[\n",
        "                {\"role\": \"system\", \"content\": \"You extract ingredients from text.\"},\n",
        "                {\"role\": \"user\", \"content\": prompt}\n",
        "            ]\n",
        "        )\n",
        "\n",
        "        extracted = response.choices[0].message.content.strip()\n",
        "        print(f\"‚úÖ Extracted: {extracted}\")\n",
        "\n",
        "        # Evaluate string safely as list (e.g., \"['eggs', 'tomatoes']\")\n",
        "        ingredients = eval(extracted)\n",
        "        return ingredients\n",
        "\n",
        "    except Exception as e:\n",
        "        print(f\"üî• Error extracting ingredients: {e}\")\n",
        "        return []\n",
        "\n",
        "#_______________________\n",
        "\n",
        "@traceable(name=\"ProcessAudioPipeline\")\n",
        "def process_audio(audio_path, mode=\"Generate New Meal Plan\"):\n",
        "    try:\n",
        "        if not audio_path:\n",
        "            print(\"‚ùå No audio path received.\")\n",
        "            return \"‚ùå Please upload a valid audio file.\"\n",
        "\n",
        "        print(\"üé§ Starting to process audio...\")\n",
        "        ingredients = speech_detector.extract_ingredients(audio_path)\n",
        "        print(f\"‚úÖ Detected Ingredients: {ingredients}\")\n",
        "\n",
        "        if not ingredients:\n",
        "            print(\"‚ùå No ingredients detected.\")\n",
        "            return \"‚ùå No ingredients could be detected from the audio.\"\n",
        "\n",
        "        print(f\"üîÑ Selected Mode: {mode}\")\n",
        "\n",
        "        if mode == \"Generate New Meal Plan\":\n",
        "            meal_plan = generate_meal_plan(ingredients)\n",
        "            print(f\"‚úÖ Generated Meal Plan.\")\n",
        "            nutrition = generate_nutrition_facts_and_advice(meal_plan)\n",
        "            print(f\"‚úÖ Generated Nutrition Advice.\")\n",
        "            output = format_output(ingredients, meal_plan, nutrition)\n",
        "            print(f\"‚úÖ Final Output Ready.\")\n",
        "            return output\n",
        "\n",
        "        elif mode == \"Search Existing Recipes\":\n",
        "            ingredient_query = \", \".join(ingredients)\n",
        "            recipes = search_recipes(ingredient_query)\n",
        "            print(f\"‚úÖ Retrieved {len(recipes)} Recipes.\")\n",
        "            return f\"\"\"üß∫ **Detected Ingredients**:\n",
        "{ingredient_query}\n",
        "\n",
        "üìö **Top Recipes**:\n",
        "\"\"\" + \"\\n\\n\".join(recipes)\n",
        "\n",
        "        else: # elif mode == \"invalid mode\"\n",
        "            print(\"‚ùå Invalid mode selected.\")\n",
        "            return \"‚ùå Invalid mode selected.\"\n",
        "\n",
        "    except Exception as e:\n",
        "        print(f\"üî• FULL ERROR TRACE: {e}\")\n",
        "        print(f\"The audio path type is: {type(audio_path)} and the mode is: {mode}\")\n",
        "        # return \"‚ùå An unexpected error occurred.\"\n",
        "        return f\"The audio path type is: {type(audio_path)} and the mode is: {mode}\"\n",
        "\n",
        "#__________________________________________________________________________________________________________________________________________________\n",
        "\n",
        "#-----------------------------------------------------------\n",
        "#         üç≥ Meal & Nutrition Generation\n",
        "#-----------------------------------------------------------\n",
        "\n",
        "@traceable(name=\"GenerateDetailedMealPlan\")\n",
        "def generate_meal_plan(ingredients_list):\n",
        "    try:\n",
        "        ingredients_query = \", \".join(ingredients_list)\n",
        "\n",
        "        prompt = f\"\"\"\n",
        "You are an AI chef. Given the following available ingredients: {ingredients_query},\n",
        "suggest one meal for breakfast, one for lunch, and one for dinner.\n",
        "\n",
        "For each meal, provide:\n",
        "- A title\n",
        "- A short list of ingredients (from what's available)\n",
        "- Simple step-by-step instructions on how to make it\n",
        "\n",
        "Use this exact format:\n",
        "\n",
        "Breakfast:\n",
        "Title: ...\n",
        "Ingredients: ...\n",
        "Instructions: ...\n",
        "\n",
        "Lunch:\n",
        "Title: ...\n",
        "Ingredients: ...\n",
        "Instructions: ...\n",
        "\n",
        "Dinner:\n",
        "Title: ...\n",
        "Ingredients: ...\n",
        "Instructions: ...\n",
        "\"\"\"\n",
        "\n",
        "        response = client.chat.completions.create(\n",
        "            model=\"gpt-3.5-turbo\",\n",
        "            messages=[\n",
        "                {\"role\": \"system\", \"content\": \"You are a professional recipe chef and meal planner.\"},\n",
        "                {\"role\": \"user\", \"content\": prompt}\n",
        "            ]\n",
        "        )\n",
        "\n",
        "        return response.choices[0].message.content\n",
        "\n",
        "    except Exception as e:\n",
        "        print(f\"üî• Error generating detailed meal plan: {e}\")\n",
        "        return \"‚ùå Error generating detailed meal plan.\"\n",
        "\n",
        "#_______________________\n",
        "\n",
        "def lookup_nutrition(meal_plan, recipes_df):\n",
        "    \"\"\"\n",
        "    Tries to match each meal in the plan to a recipe and extracts nutrition info.\n",
        "    Returns a summary string.\n",
        "    \"\"\"\n",
        "    results = []\n",
        "    for line in meal_plan.lower().splitlines():\n",
        "        if \":\" not in line:  # Skip lines without clear meal info\n",
        "            continue\n",
        "\n",
        "        label, meal = line.split(\":\", 1)\n",
        "        meal = meal.strip()\n",
        "\n",
        "        match = recipes_df[recipes_df[\"name\"].str.contains(meal, case=False, na=False)]\n",
        "        if not match.empty:\n",
        "            nutrition = match.iloc[0][\"nutrition\"]\n",
        "            try:\n",
        "                nutrition_data = ast.literal_eval(nutrition)\n",
        "                nutrition_summary = f\"Calories: {nutrition_data[0]} kcal, Fat: {nutrition_data[1]}g, Carbs: {nutrition_data[2]}g, Protein: {nutrition_data[3]}g\"\n",
        "            except Exception:\n",
        "                nutrition_summary = nutrition  # fallback if parsing fails\n",
        "        else:\n",
        "            nutrition_summary = \"Nutrition data not found.\"\n",
        "\n",
        "        results.append(f\"{label.capitalize()}: {meal} ‚û§ {nutrition_summary}\")\n",
        "\n",
        "    return \"\\n\".join(results)\n",
        "\n",
        "#_______________________\n",
        "\n",
        "def get_nutrition_info(meal_name: str) -> str:\n",
        "    \"\"\"\n",
        "    Look up nutrition info for a given meal name using the dataset.\n",
        "    \"\"\"\n",
        "    match = recipes_df[recipes_df[\"name\"].str.contains(meal_name, case=False, na=False)]\n",
        "    if not match.empty:\n",
        "        nutrition = match.iloc[0][\"nutrition\"]\n",
        "        try:\n",
        "            nutrition_data = ast.literal_eval(nutrition)\n",
        "            return f\"Calories: {nutrition_data[0]} kcal, Fat: {nutrition_data[1]}g, Carbs: {nutrition_data[2]}g, Protein: {nutrition_data[3]}g\"\n",
        "        except:\n",
        "            return nutrition  # fallback\n",
        "    else:\n",
        "        return \"Nutrition data not found.\"\n",
        "\n",
        "from langchain.tools import Tool\n",
        "\n",
        "nutrition_tool = Tool(\n",
        "    name=\"get_nutrition_info\",\n",
        "    func=get_nutrition_info,\n",
        "    description=\"Use this tool to fetch nutrition data for a meal name. Input is the meal name as a string.\"\n",
        ")\n",
        "#_______________________\n",
        "\n",
        "@traceable(name=\"GenerateNutritionAdvice\")\n",
        "def generate_nutrition_facts_and_advice(meal_plan):\n",
        "    try:\n",
        "        print(\"üß™ Meal Plan Input:\")\n",
        "        print(meal_plan)\n",
        "\n",
        "        # Step 1: Lookup Nutrition from Dataset\n",
        "        grounded_nutrition = lookup_nutrition(meal_plan, recipes_df)\n",
        "        print(\"üìä Grounded Nutrition Extracted:\")\n",
        "        print(grounded_nutrition)\n",
        "\n",
        "        # Step 2: Prepare prompt\n",
        "        prompt = f\"\"\"\n",
        "You are a nutritionist.\n",
        "\n",
        "Here is the meal plan for today:\n",
        "{meal_plan}\n",
        "\n",
        "And here are the grounded nutrition facts for each meal:\n",
        "{grounded_nutrition}\n",
        "\n",
        "Now:\n",
        "- Give a short nutritional summary for the day\n",
        "- Suggest 2 health tips to improve the meal plan\n",
        "\"\"\"\n",
        "\n",
        "        # Step 3: Run OpenAI GPT\n",
        "        print(\"üß† Sending to OpenAI...\")\n",
        "        response = client.chat.completions.create(\n",
        "            model=\"gpt-3.5-turbo\",\n",
        "            messages=[\n",
        "                {\"role\": \"system\", \"content\": \"You are a licensed dietitian.\"},\n",
        "                {\"role\": \"user\", \"content\": prompt}\n",
        "            ]\n",
        "        )\n",
        "\n",
        "        print(\"‚úÖ GPT Response Received.\")\n",
        "        return response.choices[0].message.content\n",
        "\n",
        "    except Exception as e:\n",
        "        print(f\"üî• ERROR in generate_nutrition_facts_and_advice(): {e}\")\n",
        "        return \"‚ùå Error generating nutrition advice.\"\n",
        "\n",
        "#_______________________\n",
        "\n",
        "@traceable(name=\"FormatFinalOutput\")\n",
        "def format_output(ingredients_list, meal_plan, nutrition_advice):\n",
        "    \"\"\"\n",
        "    Combines all outputs (ingredients, meals, advice) into a clean text output.\n",
        "    \"\"\"\n",
        "    try:\n",
        "        final_text = f\"\"\"üß∫ **Detected Ingredients**:\n",
        "{', '.join(ingredients_list)}\n",
        "\n",
        "üçΩÔ∏è **Meal Plan**:\n",
        "{meal_plan}\n",
        "\n",
        "üß™ **Nutrition Facts and Advice**:\n",
        "{nutrition_advice}\n",
        "\"\"\"\n",
        "        return final_text\n",
        "\n",
        "    except Exception as e:\n",
        "        print(f\"üî• Error formatting output: {e}\")\n",
        "        return \"‚ùå Error formatting final output.\"\n",
        "\n",
        "#________________________________________________________________________________________________________________________________________\n",
        "\n",
        "#------------------------------------------------------------\n",
        "#            üîç Embedding + Retrieval\n",
        "#------------------------------------------------------------\n",
        "\n",
        "@traceable(name=\"EmbedQuery\")\n",
        "def embed_query(text_query):\n",
        "    return embedding_model.embed_query(text_query)\n",
        "\n",
        "#_______________________\n",
        "\n",
        "@traceable(name=\"SearchRecipes\")\n",
        "def search_recipes(ingredient_query, top_k=5):\n",
        "    query_embedding = embed_query(ingredient_query)\n",
        "    results = collection.query(\n",
        "        query_embeddings=query_embedding,\n",
        "        n_results=top_k,\n",
        "        include=[\"documents\"]\n",
        "    )\n",
        "    return [f\"‚Ä¢ {r}\" for r in results[\"documents\"][0]]\n",
        "\n",
        "#_______________________\n",
        "\n",
        "@traceable(name=\"GetRecipeContext\")\n",
        "def get_recipe_context(ingredients_list, top_k=3):\n",
        "    ingredient_query = \", \".join(ingredients_list)\n",
        "    query_embedding = embedding_model.embed_query(ingredient_query)\n",
        "\n",
        "    results = collection.query(\n",
        "        query_embeddings=query_embedding,\n",
        "        n_results=top_k,\n",
        "        include=[\"documents\", \"metadatas\"]\n",
        "    )\n",
        "\n",
        "    context_lines = []\n",
        "    for i, doc in enumerate(results[\"documents\"][0]):\n",
        "        meta = results[\"metadatas\"][0][i]\n",
        "        cuisine = meta.get(\"cuisine_path\", \"Unknown\")\n",
        "        timing = meta.get(\"timing\", \"N/A\")\n",
        "        instructions = meta.get(\"instructions\", \"No directions available.\")\n",
        "        context_lines.append(\n",
        "            f\"‚Ä¢ {doc} ({cuisine}, takes {timing})\\nDirections: {instructions}\"\n",
        "        )\n",
        "\n",
        "    return \"\\n\\n\".join(context_lines)\n",
        "\n",
        "#____________________________________________________________________________________________________________________________________\n",
        "\n",
        "# Tool 1: Recipe Search\n",
        "recipe_tool = Tool(\n",
        "    name=\"SearchRecipe\",\n",
        "    func=search_recipes,\n",
        "    description=\"Search for recipes based on a list of ingredients.\"\n",
        ")\n",
        "\n",
        "# Tool 2: Nutrition Info Lookup\n",
        "nutrition_tool = Tool(\n",
        "    name=\"GetNutritionInfo\",\n",
        "    func=get_nutrition_info,\n",
        "    description=\"Get nutrition details for a specific meal name.\"\n",
        ")\n",
        "\n",
        "# Tool 3: Generate Meal Plan\n",
        "meal_plan_tool = Tool(\n",
        "    name=\"GenerateMealPlan\",\n",
        "    func=generate_meal_plan,\n",
        "    description=\"Generate a daily meal plan based on a list of ingredients.\"\n",
        ")\n",
        "#___________________\n",
        "from langchain.agents import initialize_agent\n",
        "from langchain.agents.agent_types import AgentType\n",
        "\n",
        "llm = ChatOpenAI(model_name=\"gpt-3.5-turbo\", temperature=0.3)\n",
        "\n",
        "agent = initialize_agent(\n",
        "    tools=[recipe_tool, nutrition_tool, meal_plan_tool],\n",
        "    llm=llm,\n",
        "    agent=AgentType.ZERO_SHOT_REACT_DESCRIPTION,\n",
        "    verbose=True\n",
        ")\n",
        "\n",
        "#____________________________________________________________________________________________________________________________________\n",
        "\n",
        "\n",
        "#--------------------------------------------------------\n",
        "#              üí¨ Assistant Chatbot\n",
        "#--------------------------------------------------------\n",
        "\n",
        "def get_context_from_query(query):\n",
        "    try:\n",
        "        results = collection.query(\n",
        "            query_embeddings=embedding_model.embed_query(query),\n",
        "            n_results=3,\n",
        "            include=[\"documents\", \"metadatas\"]\n",
        "        )\n",
        "        contexts = []\n",
        "        for doc, meta in zip(results[\"documents\"][0], results[\"metadatas\"][0]):\n",
        "            ctx = f\"{doc} | Cuisine: {meta.get('cuisine_path', 'Unknown')}, Time: {meta.get('timing', 'N/A')}, Instructions: {meta.get('instructions', 'N/A')}\"\n",
        "            contexts.append(ctx)\n",
        "        return \"\\n\\n\".join(contexts)\n",
        "    except Exception as e:\n",
        "        print(f\"‚ùå Error in get_context_from_query(): {e}\")\n",
        "        return \"No relevant recipes found.\"\n",
        "\n",
        "\n",
        "@traceable(name=\"SmartNutriChefChat\")\n",
        "def handle_chat(user_message, session_id, chat_history, last_dish):\n",
        "    try:\n",
        "        if not user_message.strip():\n",
        "            return gr.update(value=chat_history), \"\", last_dish\n",
        "\n",
        "        print(f\"üß† User input: {user_message}\")\n",
        "\n",
        "        # Handle \"how to make it\" follow-up\n",
        "        if \"how to make\" in user_message.lower() and \"it\" in user_message.lower() and last_dish:\n",
        "            user_message = f\"How do I make {last_dish}?\"\n",
        "\n",
        "        # Get recipe context for retrieval\n",
        "        recipe_context = get_context_from_query(user_message)\n",
        "\n",
        "        # Generate response using memory-aware chain\n",
        "        response = memory_chain.invoke(\n",
        "            {\"input\": user_message, \"recipe_context\": recipe_context},\n",
        "            config={\"configurable\": {\"session_id\": session_id}}\n",
        "        )\n",
        "\n",
        "        # Extract new potential dish name\n",
        "        import re\n",
        "        match = re.search(r\"(?:want|try|make|suggest(?: me)?|recipe for|dish like)\\s+([a-zA-Z\\s]+)\", user_message.lower())\n",
        "        if match:\n",
        "            candidate = match.group(1).strip()\n",
        "            if len(candidate.split()) <= 6:  # avoid noisy or vague phrases\n",
        "                last_dish = candidate\n",
        "\n",
        "        # Update chat\n",
        "        chat_history.append([user_message, response.content])\n",
        "        return gr.update(value=chat_history), \"\", last_dish\n",
        "\n",
        "    except Exception as e:\n",
        "        print(f\"üî• Error in handle_chat: {e}\")\n",
        "        return gr.update(value=chat_history), \"\", last_dish\n",
        "\n",
        "#________________________________________________________________________________________________________________________________\n",
        "\n",
        "#----------------------------------------------------\n",
        "#          üé• YouTube QA Pipeline\n",
        "#----------------------------------------------------\n",
        "\n",
        "@traceable(name=\"DownloadYouTubeAudio\")\n",
        "def download_youtube_audio(youtube_url, output_path=\"./downloads\"):\n",
        "    \"\"\"\n",
        "    Downloads audio from a YouTube video and saves as an MP3 file.\n",
        "    \"\"\"\n",
        "    try:\n",
        "        ydl_opts = {\n",
        "            'format': 'bestaudio/best',\n",
        "            'outtmpl': f'{output_path}/%(title)s.%(ext)s',\n",
        "            'postprocessors': [{\n",
        "                'key': 'FFmpegExtractAudio',\n",
        "                'preferredcodec': 'mp3',\n",
        "                'preferredquality': '192',\n",
        "            }],\n",
        "            'quiet': False\n",
        "        }\n",
        "\n",
        "        with yt_dlp.YoutubeDL(ydl_opts) as ydl:\n",
        "            info = ydl.extract_info(youtube_url, download=True)\n",
        "            filename = ydl.prepare_filename(info)\n",
        "            filename = filename.replace('.webm', '.mp3').replace('.m4a', '.mp3')\n",
        "\n",
        "        print(f\"‚úÖ Downloaded audio file: {filename}\")\n",
        "        return filename\n",
        "\n",
        "    except Exception as e:\n",
        "        print(f\"üî• Error downloading YouTube audio: {e}\")\n",
        "        return None\n",
        "\n",
        "#_______________________\n",
        "\n",
        "@traceable(name=\"TranscribeYouTubeAudio\")\n",
        "def transcribe_audio(audio_file_path):\n",
        "    \"\"\"\n",
        "    Transcribes an audio file into text using Whisper.\n",
        "    \"\"\"\n",
        "    try:\n",
        "        print(f\"üé§ Transcribing: {audio_file_path}\")\n",
        "        result = whisper_model.transcribe(audio_file_path)\n",
        "        transcript_text = result[\"text\"]\n",
        "        print(\"‚úÖ Transcription finished.\")\n",
        "        return transcript_text\n",
        "\n",
        "    except Exception as e:\n",
        "        print(f\"üî• Error during transcription: {e}\")\n",
        "        return \"‚ùå Error transcribing audio.\"\n",
        "\n",
        "#_______________________\n",
        "\n",
        "@traceable(name=\"ChunkTranscript\")\n",
        "def chunk_transcript(transcript_text, chunk_size=500):\n",
        "    \"\"\"\n",
        "    Splits a large transcript text into smaller chunks based on sentence boundaries.\n",
        "    \"\"\"\n",
        "    print(\"‚úÇÔ∏è Chunking the transcript...\")\n",
        "    chunks = []\n",
        "    current_chunk = \"\"\n",
        "\n",
        "    for sentence in transcript_text.split('. '):\n",
        "        if len(current_chunk) + len(sentence) <= chunk_size:\n",
        "            current_chunk += sentence + \". \"\n",
        "        else:\n",
        "            chunks.append(current_chunk.strip())\n",
        "            current_chunk = sentence + \". \"\n",
        "\n",
        "    # Add the last chunk if any remains\n",
        "    if current_chunk:\n",
        "        chunks.append(current_chunk.strip())\n",
        "\n",
        "    print(f\"‚úÖ Total chunks created: {len(chunks)}\")\n",
        "    return chunks\n",
        "\n",
        "# === Embedding Chunks into ChromaDB ===\n",
        "\n",
        "@traceable(name=\"EmbedAndStoreChunks\")\n",
        "def embed_and_store_chunks(chunks, youtube_url):\n",
        "    \"\"\"\n",
        "    Embeds the transcript chunks and stores them into ChromaDB.\n",
        "    \"\"\"\n",
        "    print(\"üß† Embedding chunks and saving to ChromaDB...\")\n",
        "\n",
        "    # Create IDs for each chunk\n",
        "    ids = [f\"{youtube_url}_chunk_{i}\" for i in range(len(chunks))]\n",
        "\n",
        "    # Embed all chunks\n",
        "    # embeddings = embedding_model.encode(chunks).tolist()\n",
        "    embeddings = embedding_model.embed_documents(chunks)\n",
        "\n",
        "    # Store into Chroma\n",
        "    video_collection.add(\n",
        "       documents=chunks,\n",
        "       embeddings=embeddings,\n",
        "       ids=ids,\n",
        "       metadatas=[{\"source\": youtube_url}] * len(chunks)\n",
        ")\n",
        "\n",
        "    print(f\"‚úÖ {len(chunks)} chunks embedded and saved successfully.\")\n",
        "\n",
        "\n",
        "# === Create Retriever Function ===\n",
        "\n",
        "def create_retriever():\n",
        "    \"\"\"\n",
        "    Create a retriever for the 'youtube_videos' collection.\n",
        "    \"\"\"\n",
        "    db = Chroma(\n",
        "        client=chroma_client,\n",
        "        collection_name=\"youtube_videos\",\n",
        "        embedding_function=embedding_model\n",
        "    )\n",
        "    retriever = db.as_retriever(search_kwargs={\"k\": 5})\n",
        "    return retriever\n",
        "\n",
        "# === Create QA Chain Function ===\n",
        "\n",
        "def create_qa_chain():\n",
        "    \"\"\"\n",
        "    Create a RetrievalQA chain using Chroma retriever and OpenAI LLM.\n",
        "    \"\"\"\n",
        "    retriever = create_retriever()\n",
        "    return RetrievalQA.from_chain_type(\n",
        "        llm=ChatOpenAI(model_name=\"gpt-3.5-turbo\", temperature=0),\n",
        "        retriever=retriever,\n",
        "        return_source_documents=True\n",
        "    )\n",
        "\n",
        "\n",
        "# === Handle YouTube Download, Transcription, Chunking, Embedding ===\n",
        "\n",
        "@traceable(name=\"HandleYouTubeDownload\")\n",
        "def handle_youtube_download(youtube_url):\n",
        "    if not youtube_url:\n",
        "        return \"‚ùå Please enter a valid YouTube link.\"\n",
        "\n",
        "    audio_file = download_youtube_audio(youtube_url)\n",
        "    if audio_file:\n",
        "        transcript = transcribe_audio(audio_file)\n",
        "\n",
        "        chunks = chunk_transcript(transcript)\n",
        "\n",
        "        # === NEW: Embed and Store\n",
        "        embed_and_store_chunks(chunks, youtube_url)\n",
        "\n",
        "        global qa_chain\n",
        "        qa_chain = create_qa_chain()\n",
        "\n",
        "        # === Preview first 5 chunks\n",
        "        preview_text = \"\\n\\n\".join(chunks[:5])\n",
        "\n",
        "        return preview_text\n",
        "\n",
        "    else:\n",
        "        return \"‚ùå Failed to download audio. Please check the link.\"\n",
        "\n",
        "# === QA over Video Function ===\n",
        "\n",
        "@traceable(name=\"AnswerVideoQuestion\")\n",
        "def answer_video_question(user_question):\n",
        "    \"\"\"\n",
        "    Answers a user question about the uploaded YouTube video.\n",
        "    \"\"\"\n",
        "    if not user_question:\n",
        "        return \"‚ùå Please enter a question.\"\n",
        "\n",
        "    try:\n",
        "        print(\"üîç Asking video question:\", user_question)\n",
        "\n",
        "        if qa_chain is None:\n",
        "            print(\"‚ùå qa_chain is None\")\n",
        "            return \"‚ùå QA system not initialized.\"\n",
        "\n",
        "        result = qa_chain(user_question)\n",
        "        print(\"‚úÖ Raw result from QA chain:\", result)\n",
        "\n",
        "        if \"result\" not in result:\n",
        "            print(\"‚ùå 'result' key missing in QA output.\")\n",
        "            return \"‚ùå Unexpected response format.\"\n",
        "\n",
        "        return result[\"result\"]\n",
        "\n",
        "    except Exception as e:\n",
        "        print(f\"üî• Error during video QA: {e}\")\n",
        "        return f\"‚ùå Error: {e}\"\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2KFD1sbeKS1W"
      },
      "source": [
        "### ‚úÖ Evaluation / Testing"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bviYNzuvQiH_",
        "outputId": "60740962-9eab-4876-cf9f-1b7dcbf4e22d"
      },
      "outputs": [],
      "source": [
        "# from langchain.evaluation import run_on_dataset\n",
        "# from langsmith.evaluation import Example, LangChainStringEvaluator\n",
        "from langchain.evaluation.loading import load_dataset\n",
        "from langchain.evaluation.schema import StringEvaluator\n",
        "\n",
        "# === Define AI Judge ===\n",
        "from langchain.agents import initialize_agent\n",
        "from langchain.chat_models import ChatOpenAI\n",
        "from langchain.evaluation.criteria.eval_chain import CriteriaEvalChain\n",
        "\n",
        "# === 1. Define the Nutrition Tool ===\n",
        "nutrition_tool = Tool(\n",
        "    name=\"get_nutrition_info\",\n",
        "    func=get_nutrition_info,\n",
        "    description=\"Use this tool to fetch nutrition data for a meal name. Input is the meal name as a string.\"\n",
        ")\n",
        "\n",
        "# === 2. Initialize an LLM for both tools and evaluation ===\n",
        "llm = ChatOpenAI(model_name=\"gpt-3.5-turbo\", temperature=0)\n",
        "\n",
        "# === 3. Create a LangChain Agent that can use your tool ===\n",
        "agent = initialize_agent(\n",
        "    tools=[nutrition_tool],\n",
        "    llm=llm,\n",
        "    agent=\"zero-shot-react-description\",\n",
        "    verbose=True\n",
        ")\n",
        "\n",
        "# === 4. Run a test question with the tool ===\n",
        "print(\"üîç Tool Output:\")\n",
        "print(agent.run(\"What are the nutrition facts for Tomato Omelette?\"))\n",
        "\n",
        "# === 5. Define your LangChain Evaluator (LangSmith compatible) ===\n",
        "meal_plan_evaluator = CriteriaEvalChain.from_llm(\n",
        "    llm=llm,\n",
        "    criteria={\n",
        "        \"relevance\": \"Does the meal plan match the detected ingredients?\",\n",
        "        \"completeness\": \"Does it cover all 3 main meals (breakfast, lunch, dinner)?\",\n",
        "        \"creativity\": \"Is the meal plan creative and varied?\"\n",
        "    }\n",
        ")\n",
        "\n",
        "# === 6. Evaluation Function ===\n",
        "def evaluate_output(ingredients_list, meal_plan_text):\n",
        "    try:\n",
        "        # Format input for evaluator\n",
        "        inputs = {\"ingredients\": \", \".join(ingredients_list)}\n",
        "        prediction = {\"meal_plan\": meal_plan_text}\n",
        "\n",
        "        # Run evaluation\n",
        "        result = meal_plan_evaluator.evaluate_strings(\n",
        "            input=inputs,\n",
        "            prediction=prediction\n",
        "        )\n",
        "\n",
        "        print(\"üß† Judgment:\", result[\"reasoning\"])\n",
        "        print(\"üìä Score:\", result[\"score\"])\n",
        "        return result\n",
        "\n",
        "    except Exception as e:\n",
        "        print(f\"üî• Error during evaluation: {e}\")\n",
        "        return None\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "89NzlVt_Qnba",
        "outputId": "8ebf8278-fcd5-49ba-daf9-ddca97433c42"
      },
      "outputs": [],
      "source": [
        "# === Example Evaluation Run ===\n",
        "ingredients_used = [\"cheese\", \"bread\", \"tomatoes\"]\n",
        "\n",
        "meal_plan_generated = \"\"\"\n",
        "Breakfast: Cheese Omelette\n",
        "Lunch: Tomato Sandwich\n",
        "Dinner: Grilled Cheese with Tomato Soup\n",
        "\"\"\"\n",
        "\n",
        "# Run evaluation\n",
        "result = evaluate_output(ingredients_used, meal_plan_generated)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "svB217mrXCIF"
      },
      "source": [
        "## üìç Step 3: App Layout\n",
        "The app will have two tabs:\n",
        "- üì∑ Upload Image (Vision)\n",
        "- üé§ Record Voice (Speech-to-Text)\n",
        "Each will detect ingredients, retrieve recipes, plan meals, and show nutrition."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 680
        },
        "id": "Y9A5kPniWzQs",
        "outputId": "ac331ed1-1956-4035-a92a-c7a8e592e120"
      },
      "outputs": [],
      "source": [
        "custom_css = \"\"\"\n",
        "body {\n",
        "    background: linear-gradient(to right, #fdf6e3, #fefcea);\n",
        "    font-family: 'Segoe UI', sans-serif;\n",
        "}\n",
        "\n",
        ".gr-button {\n",
        "    border-radius: 12px !important;\n",
        "    font-weight: bold !important;\n",
        "    padding: 8px 16px !important;\n",
        "    box-shadow: 1px 1px 3px rgba(0, 0, 0, 0.1);\n",
        "}\n",
        "\n",
        ".gr-button:hover {\n",
        "    background-color: #f4e4c1 !important;\n",
        "    color: #333 !important;\n",
        "}\n",
        "\n",
        ".gr-textbox textarea, .gr-radio label {\n",
        "    border-radius: 8px !important;\n",
        "    background-color: #fffefc !important;\n",
        "}\n",
        "\n",
        ".gr-chatbot {\n",
        "    background-color: #fffdfa !important;\n",
        "    border-radius: 10px;\n",
        "    border: 1px solid #f0e9dc;\n",
        "}\n",
        "\"\"\"\n",
        "\n",
        "with gr.Blocks(css=custom_css) as demo:\n",
        "\n",
        "    chat_history = gr.State([])\n",
        "    session_id = gr.State(get_session_id())\n",
        "    last_dish_state = gr.State(\"\")\n",
        "\n",
        "\n",
        "    gr.Markdown(\"\"\"\n",
        "    <h1 style='text-align: center; color: #5c4b2c;'>üçΩÔ∏è NutriChef AI</h1>\n",
        "    <p style='text-align: center; font-size: 17px;'>Your Friendly AI Chef ‚Äî Generate meal plans, extract nutrition, and answer food questions from image, audio, or video! üéâ</p>\n",
        "    \"\"\")\n",
        "\n",
        "    with gr.Tab(\"üì∑ Upload Fridge Image\"):\n",
        "        with gr.Row():\n",
        "            with gr.Column():\n",
        "                image_input = gr.Image(type=\"pil\", label=\"Upload Fridge Image\")\n",
        "                meal_mode = gr.Radio(\n",
        "                    choices=[\"Generate New Meal Plan\", \"Search Existing Recipes\"],\n",
        "                    label=\"Choose Task\",\n",
        "                    value=\"Generate New Meal Plan\"\n",
        "                )\n",
        "                submit_image = gr.Button(\"üç≥ Find My Meals!\", elem_id=\"btn-image\")\n",
        "\n",
        "            with gr.Column():\n",
        "                output_text_image = gr.Textbox(label=\"NutriChef Output\", lines=10)\n",
        "\n",
        "        submit_image.click(\n",
        "            process_image,\n",
        "            inputs=[image_input, meal_mode],\n",
        "            outputs=[output_text_image]\n",
        "        )\n",
        "\n",
        "    with gr.Tab(\"üé§ Upload Ingredients Audio\"):\n",
        "        with gr.Row():\n",
        "            with gr.Column():\n",
        "                audio_input = gr.Audio(sources=[\"upload\"], type=\"filepath\", label=\"Upload Audio (e.g. 'I have eggs and cheese')\")\n",
        "                meal_mode_audio = gr.Radio(\n",
        "                    choices=[\"Generate New Meal Plan\", \"Search Existing Recipes\"],\n",
        "                    label=\"Choose Task\",\n",
        "                    value=\"Generate New Meal Plan\"\n",
        "                )\n",
        "                submit_audio = gr.Button(\"üé§ Find My Meals!\", elem_id=\"btn-audio\")\n",
        "\n",
        "            with gr.Column():\n",
        "                output_text_audio = gr.Textbox(label=\"NutriChef Output\", lines=10)\n",
        "\n",
        "        submit_audio.click(\n",
        "            process_audio,\n",
        "            inputs=[audio_input, meal_mode_audio],\n",
        "            outputs=[output_text_audio]\n",
        "        )\n",
        "\n",
        "    with gr.Tab(\"üìπ Upload Cooking Video\"):\n",
        "        with gr.Row():\n",
        "            with gr.Column():\n",
        "                youtube_link = gr.Textbox(\n",
        "                    label=\"Paste YouTube Link\",\n",
        "                    placeholder=\"https://www.youtube.com/watch?v=example\"\n",
        "                )\n",
        "                download_button = gr.Button(\"üé• Analyze Video\", elem_id=\"btn-video\")\n",
        "\n",
        "                user_question = gr.Textbox(\n",
        "                    label=\"Ask a Question About the Video\",\n",
        "                    placeholder=\"e.g. What did the chef cook for dinner?\"\n",
        "                )\n",
        "                ask_button = gr.Button(\"Ask\", elem_id=\"btn-ask\")\n",
        "\n",
        "            with gr.Column():\n",
        "                transcript_output = gr.Textbox(\n",
        "                    label=\"üìú Transcript Preview\",\n",
        "                    placeholder=\"Transcript will appear here...\",\n",
        "                    lines=10\n",
        "                )\n",
        "                answer_output = gr.Textbox(\n",
        "                    label=\"Answer\",\n",
        "                    placeholder=\"AI response will appear here...\",\n",
        "                    lines=5\n",
        "                )\n",
        "\n",
        "        download_button.click(\n",
        "            handle_youtube_download,\n",
        "            inputs=[youtube_link],\n",
        "            outputs=[transcript_output]\n",
        "        )\n",
        "\n",
        "        ask_button.click(\n",
        "            answer_video_question,\n",
        "            inputs=[user_question],\n",
        "            outputs=[answer_output]\n",
        "        )\n",
        "\n",
        "    ingredients_state = gr.State()\n",
        "    meal_plan_state = gr.State()\n",
        "\n",
        "    with gr.Accordion(\"üí¨ NutriChef AI Assistant Chat\", open=False):\n",
        "        chatbot = gr.Chatbot(label=\"NutriChef Chat\", value=[])\n",
        "        user_message = gr.Textbox(label=\"Your Message\", placeholder=\"Ask me anything...\")\n",
        "        send_button = gr.Button(\"üí¨ Send\")\n",
        "\n",
        "        def chat_with_memory(user_message, session_id, chat_history, last_dish):\n",
        "            try:\n",
        "                user_message = user_message.strip()\n",
        "                if not user_message:\n",
        "                   return gr.update(value=chat_history), \"\", last_dish\n",
        "\n",
        "                original_message = user_message  # Keep for dish detection\n",
        "\n",
        "                # Handle vague follow-ups referring to a previous dish\n",
        "                vague_phrases = [\n",
        "                    \"how to make it\", \"how do i make it\",\n",
        "                    \"is it healthy\", \"how much time\", \"can i add\", \"should i use\"\n",
        "        ]\n",
        "                if any(phrase in user_message.lower() for phrase in vague_phrases) and last_dish:\n",
        "                  llm_input = f\"{user_message} (referring to {last_dish})\"\n",
        "                else:\n",
        "                  llm_input = user_message\n",
        "\n",
        "                # Retrieve context from Chroma\n",
        "                recipe_context = get_context_from_query(user_message)\n",
        "\n",
        "                # Generate response using memory\n",
        "                response = memory_chain.invoke(\n",
        "                   {\"input\": llm_input, \"recipe_context\": recipe_context},\n",
        "                   config={\"configurable\": {\"session_id\": session_id}}\n",
        "        )\n",
        "\n",
        "                # Detect if a new dish is mentioned and store it\n",
        "                new_dish = detect_dish_with_llm(original_message)\n",
        "                if new_dish.lower() == \"none\":\n",
        "                   new_dish = extract_dish_name(original_message)\n",
        "                if new_dish and new_dish.lower() != \"none\":\n",
        "                   last_dish = new_dish\n",
        "\n",
        "                # Update chat UI\n",
        "                chat_history.append([user_message, response.content])\n",
        "                return gr.update(value=chat_history), \"\", last_dish\n",
        "\n",
        "            except Exception as e:\n",
        "              print(f\"üî• Error in chat_with_memory(): {e}\")\n",
        "              return gr.update(value=chat_history), \"\", last_dish\n",
        "\n",
        "\n",
        "        send_button.click(\n",
        "          chat_with_memory,\n",
        "          inputs=[user_message, session_id, chat_history, last_dish_state],\n",
        "          outputs=[chatbot, user_message, last_dish_state]\n",
        ")\n",
        "\n",
        "\n",
        "demo.launch() # debug=True\n"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "L4",
      "machine_shape": "hm",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "venv",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.11.9"
    },
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "027da485715142c38a2c26789c73d7b2": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "0423a2e9a0c348ef98ee471c0c25eb3c": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "042b770a7a974f44a90b57e67653f88b": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HBoxModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_afda3fe3b30246fcaaed8dbbb10da920",
              "IPY_MODEL_1df5977bb6eb440dbac7806db50544d4",
              "IPY_MODEL_79b11639e16540eb895603f7e91a17d4"
            ],
            "layout": "IPY_MODEL_859f5ba18cb547008dcaa867f7b85be0"
          }
        },
        "05c1bf9e69034a4da04987e5f1db0da2": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "FloatProgressModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_326c3d2c214f4da4a71863164ac7b2f8",
            "max": 266,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_9b7b5890a3ec40faaed455580a5c975b",
            "value": 266
          }
        },
        "1c916077648a41148c42103ec65eccea": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "1df5977bb6eb440dbac7806db50544d4": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "FloatProgressModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_fba2200969c64ee0afec16ea7bde00a5",
            "max": 69556,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_94bb5e8bb23f42098d7f42d0961e8321",
            "value": 69556
          }
        },
        "2049e5a7e7034ee9a474f0660afda01b": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "23c205f825454f02ac00e12021f259ff": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_64113a256757492592f1520842eb2d68",
            "placeholder": "‚Äã",
            "style": "IPY_MODEL_0423a2e9a0c348ef98ee471c0c25eb3c",
            "value": "model.safetensors:‚Äá100%"
          }
        },
        "326c3d2c214f4da4a71863164ac7b2f8": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "34582e88f5634016b1734b7454fa513f": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_ead270f9e4c54b04938d1656b1ba5722",
            "placeholder": "‚Äã",
            "style": "IPY_MODEL_3cb6d5e84e624bd297af584d8c4aa55a",
            "value": "preprocessor_config.json:‚Äá100%"
          }
        },
        "3cb6d5e84e624bd297af584d8c4aa55a": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "4dc5b4b7f68340ea8f55cc79a523fa36": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "50a7dde59a6b4a169c2f6e1250e97206": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "61553f3c015841b587983d99c9eea071": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "FloatProgressModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_e9915487dff84ead82431d5f6ca1f39d",
            "max": 102482854,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_addf25ab3bfb4b20ac9b754f5a1a00ae",
            "value": 102482854
          }
        },
        "64113a256757492592f1520842eb2d68": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "696e94322bde45429eb382e6131ee713": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HBoxModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_34582e88f5634016b1734b7454fa513f",
              "IPY_MODEL_05c1bf9e69034a4da04987e5f1db0da2",
              "IPY_MODEL_cc5b6a9306e24866b435aa735994cf0e"
            ],
            "layout": "IPY_MODEL_6e0f4a000c3c4064872acb242b595be0"
          }
        },
        "6e0f4a000c3c4064872acb242b595be0": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "79b11639e16540eb895603f7e91a17d4": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_1c916077648a41148c42103ec65eccea",
            "placeholder": "‚Äã",
            "style": "IPY_MODEL_50a7dde59a6b4a169c2f6e1250e97206",
            "value": "‚Äá69.6k/69.6k‚Äá[00:00&lt;00:00,‚Äá4.23MB/s]"
          }
        },
        "859f5ba18cb547008dcaa867f7b85be0": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "94bb5e8bb23f42098d7f42d0961e8321": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "ProgressStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "971185292cf747e593dd19c173f48f61": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "9a8e21dbb5804af880a6133a836a030f": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HBoxModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_23c205f825454f02ac00e12021f259ff",
              "IPY_MODEL_61553f3c015841b587983d99c9eea071",
              "IPY_MODEL_eec68c0b6c444ad9a0ec7e89a29594f1"
            ],
            "layout": "IPY_MODEL_d68ddb5cc69d49d4bb53e1fdf46836c5"
          }
        },
        "9b7b5890a3ec40faaed455580a5c975b": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "ProgressStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "addf25ab3bfb4b20ac9b754f5a1a00ae": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "ProgressStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "afda3fe3b30246fcaaed8dbbb10da920": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_f6901a26bf4442d5a0a80db84eb0eac9",
            "placeholder": "‚Äã",
            "style": "IPY_MODEL_4dc5b4b7f68340ea8f55cc79a523fa36",
            "value": "config.json:‚Äá100%"
          }
        },
        "cc5b6a9306e24866b435aa735994cf0e": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_2049e5a7e7034ee9a474f0660afda01b",
            "placeholder": "‚Äã",
            "style": "IPY_MODEL_027da485715142c38a2c26789c73d7b2",
            "value": "‚Äá266/266‚Äá[00:00&lt;00:00,‚Äá31.3kB/s]"
          }
        },
        "cd53374fd02748e08b8683ade74a002e": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "d68ddb5cc69d49d4bb53e1fdf46836c5": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "e9915487dff84ead82431d5f6ca1f39d": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "ead270f9e4c54b04938d1656b1ba5722": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "eec68c0b6c444ad9a0ec7e89a29594f1": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_971185292cf747e593dd19c173f48f61",
            "placeholder": "‚Äã",
            "style": "IPY_MODEL_cd53374fd02748e08b8683ade74a002e",
            "value": "‚Äá102M/102M‚Äá[00:00&lt;00:00,‚Äá239MB/s]"
          }
        },
        "f6901a26bf4442d5a0a80db84eb0eac9": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "fba2200969c64ee0afec16ea7bde00a5": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        }
      }
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
